{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading pretrained weight and config file\n",
    "net = cv2.dnn.readNet('yolov3.weights', 'yolov3_testing.cfg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract the objects from the file\n",
    "classes = []\n",
    "with open(\"classes.txt\", \"r\") as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person', 'bicycle', 'car', 'motorbike', 'aeroplane']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the image\n",
    "img = cv2.imread('cars.jpg')\n",
    "height,width,_ = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1/255 : To normalize\n",
    "#(416,216) : Size of Image\n",
    "#(0,0,0) : Not doing any mean subtraction\n",
    "#swapRB : To convert to RGB\n",
    "blob = cv2.dnn.blobFromImage(img, 1/255, (416, 416), (0,0,0), swapRB=True, crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Input blob to network\n",
    "net.setInput(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get the output layer names\n",
    "output_layers_names = net.getUnconnectedOutLayersNames()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To get output from forward pass\n",
    "layerOutputs = net.forward(output_layers_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes = []\n",
    "confidences = []\n",
    "class_ids = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First for loop Extract Info from layered output\n",
    "#Second for loop Extract Info from each of the output\n",
    "for output in layerOutputs:\n",
    "    for detection in output:\n",
    "        scores = detection[5:]\n",
    "        class_id = np.argmax(scores)\n",
    "        confidence = scores[class_id]\n",
    "        if confidence > 0.8:\n",
    "            #Here the value is normalized to get back the original valule multiply by heigt & width\n",
    "            center_x = int(detection[0]*width)\n",
    "            center_y = int(detection[1]*height)\n",
    "            w = int(detection[2]*width)\n",
    "            h = int(detection[3]*height)\n",
    "\n",
    "            #Yolo predicts the output w.r.t to bounding boxes, inorder to get the upper left cornor position do the below calculation\n",
    "            x = int(center_x - w/2)\n",
    "            y = int(center_y - h/2)\n",
    "\n",
    "            boxes.append([x, y, w, h])\n",
    "            confidences.append((float(confidence)))\n",
    "            class_ids.append(class_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non max suppression\n",
    "#Threshold: 0.5\n",
    "#long maximum suppression : 04 by default\n",
    "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  1, 16,  7, 26,  5, 28,  3, 19, 22, 24, 15, 14])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexes.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = cv2.FONT_HERSHEY_PLAIN\n",
    "colors = np.random.uniform(0, 255, size=(len(boxes), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(indexes)>0:\n",
    "    for i in indexes.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        label = str(classes[class_ids[i]])\n",
    "        confidence = str(round(confidences[i],2))\n",
    "        color = colors[i]\n",
    "        cv2.rectangle(img, (x,y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(img, label + \" \" + confidence, (x, y+20), font, 2, (255,255,255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('Image', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
